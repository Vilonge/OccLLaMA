<!DOCTYPE html>
<html>


<!-- icon -->

<head>
    <meta charset="utf-8">
    <meta name="description" content="OccLLaMA">
    <meta name="keywords" content="Robotics, Quadruped, Whole-body Control, Whole-body Manipulation">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>
        OccLLaMA
    </title>

    <!-- 设置网站图标（favicon）- 将icon.png替换为你的新图标文件 -->

    <link rel="icon" href="./static/images/logo.png">

    <!-- Google Analytics 跟踪代码 -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-QZ38WT2YPD"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }
        gtag('js', new Date());

        gtag('config', 'G-QZ38WT2YPD');
    </script>

    <!-- 引入Google字体 -->
    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <!-- 引入Bulma CSS框架及其组件 -->
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">

    <!-- 引入学术图标库 -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

    <!-- 引入自定义CSS样式 -->
    <link rel="stylesheet" href="./static/css/index.css">

    <!-- 引入Font Awesome图标库 -->
    <script src="https://kit.fontawesome.com/19914a84eb.js" crossorigin="anonymous"></script>

    <!-- 引入jQuery库 -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>

    <!-- 引入Bulma的JavaScript组件 -->
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>

    <!-- 引入自定义JavaScript文件 -->
    <script src="./static/js/index.js"></script>

</head>



<section class="hero">
    <div class="hero-body">
        <div class="container">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">
                        <img src="./static/images/logo.png" alt="logo" style="height: 1.1em; vertical-align: middle; margin-right: -0.2rem;">OccLLaMA: A Unified Occupancy-Language-Action World Model for Understanding and Generation Tasks in Autonomous
                        Driving
                    </h1>

                    <div class="is-size-4 publication-authors">
                        <span class="author-block" style="font-size: 95%;">
                          <a href="https://vilonge.github.io/">Julong Wei<sup>1</sup></a>,&nbsp;
                          <a href="https://github.com/SS-Yuan">Shanshuai Yuan<sup>1</sup></a>,&nbsp;
                          <a href="https://philipflyg.github.io/">Pengfei Li<sup>2</sup></a>,&nbsp;
                          <a href="https://github.com/Keirra0116">Xinyi Quan<sup>1</sup></a>,&nbsp;
                          <a href="https://onlytailei.github.io/">Lei Tai<sup>4</sup></a>,&nbsp;
                          <a href="https://zjru.github.io/">Jieru Zhao<sup>3</sup></a>,&nbsp;
                          <a href="https://faet.fudan.edu.cn/e4/72/c23898a255090/page.htm">Zhongxue Gan<sup>1</sup></a>,&nbsp;
                          <a href="https://wenchaoding.github.io/">Wenchao Ding<sup>1</sup></a>
                        </span>
                    </div>

                    <div class="column">
                        <image src="./static/images/ip.png" style="width: 50%;"></image>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">

                
                <a href="./static/OccLLaMA.pdf"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                            <span>PDF
                            </span>
                            </a>
                            </span>
                            <!-- arXiv Link. -->
                            <span class="link-block">


                <a href="https://arxiv.org/abs/2409.03272"
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                            <span>ArXiv</span>
                            </a>
                            </span>
                            <span class="link-block">

                <!-- TODO:update -->
                <a href="#" class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                            <span>Code</span>
                            </a>
                            </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- video -->
<section class="section">
    <div class="container">
        <div class="columns is-centered">
            <div class="column is-full-width has-text-centered">
                <iframe width="100%" height="450" src="https://www.youtube.com/embed/TB3oEbL3dSo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen style="max-width: 800px; display: block; margin: 0 auto;"></iframe>
            </div>
        </div>
    </div>
</section>


<!-- abstract -->
<section class="section">
    <div class="container">
        <!-- Abstract. -->
        <div class="columns is-centered has-text-centered">
            <div class="column is-two-thirds">
                <h2 class="title is-2">Abstract</h2>
                <div class="content has-text-justified">
                    <p>
                        Scene understanding via multi-modal large language models (MLLMs) and scene forecasting with world models have advanced the development of autonomous driving. The former maps visual inputs to driving-specific outputs, neglecting spatial reasoning and
                        world dynamics. The latter captures world dynamics, lacking comprehensive scene understanding. In contrast, humans seamlessly integrate understanding, forecasting, and decision-making via multi-modal representations, avoiding misalignment
                        and complexity.
                    </p>
                    <p>To this end, we propose <span class="method" style="color: red; font-weight: bold;">OccLLaMA</span>, a unified occupancy-language-action world model for multi-task learning. It uses semantic occupancy as a unified and modality-agnostic
                        3D visual representation, effectively integrating spatial scene understanding and scene forecasting. We further introduce a novel scene tokenizer tailored for occupancy, enabling a unified representation manner for multi-task across
                        understanding and generation. Furthermore, we enhance LLM, specifically LLaMA, to enable end-to-end multi-task learning within a unified auto-regressive framework.
                    </p>
                    <p>Extensive experiments demonstrate that OccLLaMA not only achieves competitive performance on multi-task,including scene understanding, occupancy forecasting and motion planning, but also significantly enhances motion planning performance
                        by the integration of multi-task learning, showcasing its effectiveness and potential as a foundation model for autonomous driving.
                    </p>
                </div>
            </div>
        </div>
    </div>
</section>


<!-- framework -->
<section class="section">
    <div class="container">
        <h2 class="title is-2" style="text-align: center;">Framework</h2>
        <div class="columns is-centered">
            <div class="column is-full-width has-text-centered">
                <img src="./static/images/pipeline.png" alt="" style="width: 100%; max-width: 100%; height: auto; display: block; margin: 0 auto;" />
                <p class="caption" style="margin-top: 10px; font-size: 0.9em; text-align: justify;">
                    The Scene Tokenizer and Unified World Model are core components of OccLLaMA. The Scene Tokenizer employs a sparse encoder and decoupled decoder to efficiently tokenize the occupancy scene, addressing data sparsity and class imbalance. The Unified World
                    Model integrates occupancy-language-action modalities within a unified discrete auto-regressive framework, supporting multi-task learning in autonomous driving.
                </p>
            </div>
        </div>
    </div>
</section>


<section class="section">
    <div class="container">
        <h2 class="title is-2" style="text-align: center; font-size: 2.4rem; color: #333;">Experiments</h2>

        <!-- Experiment selection buttons -->
        <div class="columns is-centered" style="margin-bottom: 2rem;">
            <div class="column has-text-centered">
                <button class="button is-light experiment-btn" data-target="exp1" style="border-radius: 8px; padding: 1.2rem 2.2rem; font-size: 1.2rem; background-color: #f5f5f5; width: 90%; color: #333;">Scene Understanding</button>
            </div>
            <div class="column has-text-centered">
                <button class="button is-light experiment-btn" data-target="exp2" style="border-radius: 8px; padding: 1.2rem 2.2rem; font-size: 1.2rem; background-color: #f5f5f5; width: 90%; color: #333;">Occupancy Forecasting</button>
            </div>
            <div class="column has-text-centered">
                <button class="button is-light experiment-btn" data-target="exp3" style="border-radius: 8px; padding: 1.2rem 2.2rem; font-size: 1.2rem; background-color: #f5f5f5; width: 90%; color: #333;">Motion Planning</button>
            </div>
        </div>

        <!-- Experiment content display area -->
        <div class="columns is-centered">
            <div class="column is-full-width has-text-centered">
                <!-- Experiment 1 content -->
                <div id="exp1" class="experiment-content">
                    <img src="./static/images/scene_understand.png" alt="scene_understand" style="width: 100%; max-width: 100%; height: auto; display: block; margin: 0 auto;" />
                    <p class="caption" style="margin-top: 10px; font-size: 1.1em; text-align: justify; color: #333;">
                        OccLLaMA enables scene understanding with spatial reasoning based on occupancy observation and enhances motion planning as a prerequisite chain-of-though
                    </p>
                </div>

                <!-- Experiment 2 content -->
                <div id="exp2" class="experiment-content" style="display: none;">
                    <img src="./static/images/fore.png" alt="fore" style="width: 100%; max-width: 100%; height: auto; display: block; margin: 0 auto;" />
                    <p class="caption" style="margin-top: 10px; font-size: 1.1em; text-align: justify; color: #333;">
                        OccLLaMA demonstrates superior long-term forecasting performance, both static scenes evolution (Zoom In, Left) and dynamic objects motion (Zoom In, Right).
                    </p>
                </div>

                <!-- Experiment 3 content -->
                <div id="exp3" class="experiment-content" style="display: none;">
                    <img src="./static/images/plan.png" alt="plan" style="width: 75%; max-width: 75%; height: auto; display: block; margin: 0 auto;" />
                    <p class="caption" style="margin-top: 10px; font-size: 1.1em; text-align: justify; color: #333; width: 75%; margin-left: auto; margin-right: auto;">
                        OccLLaMA constructs a human-like motion planning process by integrating scene understanding as a prerequisite task and alternately forecasting scenes and planning waypoints </p>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Add button click event
        document.querySelectorAll('.experiment-btn').forEach(button => {
            button.addEventListener('click', function() {
                // Hide all experiment content
                document.querySelectorAll('.experiment-content').forEach(content => {
                    content.style.display = 'none';
                });

                // Show selected experiment content
                const target = this.getAttribute('data-target');
                document.getElementById(target).style.display = 'block';
            });
        });
    </script>
</section>




<!-- bibinfo -->
<section class="section" id="BibTeX">
    <div class="container content">
        <h2 class="titile">BibTeX</h2>
        <pre><code>@article{wei2024occllama,
    title={Occllama: An occupancy-language-action generative world model for autonomous driving},
    author={Wei, Julong and Yuan, Shanshuai and Li, Pengfei and Hu, Qingda and Gan, Zhongxue and Ding, Wenchao},
    journal={arXiv preprint arXiv:2409.03272},
    year={2024}
}</code></pre>
    </div>
</section>


<footer class="footer" style="padding: 0.2rem 0;">
    <div class="container">
        <div class="content has-text-centered">
            <p>Page template borrowed from <a href="https://lecar-lab.github.io/falcon-humanoid/"><span class="dnerf">FALCON</span></a>.</p>
        </div>
    </div>
</footer>

</body>

</html>